{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "from util import load_data, separate_data, train, test\n",
    "from models.graphcnn import GraphCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(dataset: str,\n",
    "         device: int = 0,\n",
    "         batch_size: int = 32,\n",
    "         iters_per_epoch: int = 1000,\n",
    "         epochs: int = 350,\n",
    "         lr: float = 0.01,\n",
    "         seed: int = 0,\n",
    "         fold_idx: int = 0,\n",
    "         num_layers: int = 5,\n",
    "         num_mlp_layers: int = 2,\n",
    "         hidden_dim: int = 64,\n",
    "         final_dropout: float = 0.5,\n",
    "         graph_pooling_type: str = 'sum',\n",
    "         neighbor_pooling_type: str = 'sum',\n",
    "         learn_eps:bool = True,\n",
    "         degree_as_tag:bool = True,\n",
    "         filename: str = 'output file'):\n",
    "    '''\n",
    "    PyTorch graph convolutional neural net for whole-graph classification.\n",
    "\n",
    "    Parameters:\n",
    "    - dataset_name (str): Name of the dataset. Default is 'MUTAG'.\n",
    "    - device (int): GPU device to use if any. Default is 0.\n",
    "    - batch_size (int): Input batch size for training. Default is 32.\n",
    "    - iters_per_epoch (int): Number of iterations per epoch. Default is 1000.\n",
    "    - epochs (int): Number of epochs to train. Default is 350.\n",
    "    - lr (float): Learning rate. Default is 0.01.\n",
    "    - seed (int): Random seed for splitting the dataset into 10. Default is 0.\n",
    "    - fold_idx (int): Index of fold in 10-fold validation. Should be less then 10. Default is 0.\n",
    "    - num_layers (int): Number of layers, INCLUDING the input one. Default is 5.\n",
    "    - num_mlp_layers (int): Number of layers for MLP, EXCLUDING the input one. Default is 2.\n",
    "    - hidden_dim (int): Number of hidden units. Default is 64.\n",
    "    - final_dropout (float): Final layer dropout. Default is 0.5.\n",
    "    - graph_pooling_type (str): Pooling for over nodes in a graph. Default is 'sum'. Choices = [\"sum\", \"average\"].\n",
    "    - neighbor_pooling_type (str): Pooling for over neighboring nodes. Default is 'sum'. Choices=[\"sum\", \"average\", \"max\"].\n",
    "    - learn_eps (bool): Whether to learn the epsilon weighting for the center nodes. Does not affect training accuracy though.\n",
    "    - degree_as_tag (bool): Let the input node features be the degree of nodes (heuristics for unlabeled graph). \n",
    "    - filename (str): Output file name. Default is 'output file'.\n",
    "    '''\n",
    "\n",
    "    # Training 50\n",
    "    # Note: Hyper-parameters need to be tuned in order to obtain results reported in the paper.\n",
    "\n",
    "    #set up seeds and gpu device\n",
    "    torch.manual_seed(0)\n",
    "    np.random.seed(0)    \n",
    "    device = torch.device(\"cuda:\" + str(device)) if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(0)\n",
    "\n",
    "    graphs, num_classes = load_data(dataset, degree_as_tag)\n",
    "\n",
    "    ##10-fold cross validation. Conduct an experiment on the fold specified by fold_idx.\n",
    "    train_graphs, test_graphs = separate_data(graphs, seed, fold_idx)\n",
    "\n",
    "    model = GraphCNN(num_layers, num_mlp_layers, train_graphs[0].node_features.shape[1], hidden_dim, num_classes, final_dropout, learn_eps, graph_pooling_type, neighbor_pooling_type, device).to(device)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.5)\n",
    "\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        scheduler.step()\n",
    "\n",
    "        avg_loss = train(model, device, train_graphs, optimizer, epoch, iters_per_epoch, batch_size)\n",
    "        acc_train, acc_test = test(model, device, train_graphs, test_graphs, epoch)\n",
    "\n",
    "        if not filename == \"\":\n",
    "            with open(filename, 'w') as f:\n",
    "                f.write(\"%f %f %f\" % (avg_loss, acc_train, acc_test))\n",
    "                f.write(\"\\n\")\n",
    "        print(\"\")\n",
    "\n",
    "        print(model.eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- dataset_name (str): Name of the dataset. Default is 'MUTAG'.\n",
    "- device (int): GPU device to use if any. Default is 0.\n",
    "- batch_size (int): Input batch size for training. Default is 32.\n",
    "- iters_per_epoch (int): Number of iterations per epoch. Default is 1000.\n",
    "- epochs (int): Number of epochs to train. Default is 350.\n",
    "- lr (float): Learning rate. Default is 0.01.\n",
    "- seed (int): Random seed for splitting the dataset into 10. Default is 0.\n",
    "- fold_idx (int): Index of fold in 10-fold validation. Should be less then 10. Default is 0.\n",
    "- num_layers (int): Number of layers, INCLUDING the input one. Default is 5.\n",
    "- num_mlp_layers (int): Number of layers for MLP, EXCLUDING the input one. Default is 2.\n",
    "- hidden_dim (int): Number of hidden units. Default is 64.\n",
    "- final_dropout (float): Final layer dropout. Default is 0.5.\n",
    "- graph_pooling_type (str): Pooling for over nodes in a graph. Default is 'sum'. Choices = [\"sum\", \"average\"].\n",
    "- neighbor_pooling_type (str): Pooling for over neighboring nodes. Default is 'sum'. Choices=[\"sum\", \"average\", \"max\"].\n",
    "- learn_eps (bool): Whether to learn the epsilon weighting for the center nodes. Does not affect training accuracy though.\n",
    "- degree_as_tag (bool): Let the input node features be the degree of nodes (heuristics for unlabeled graph). \n",
    "- filename (str): Output file name. Default is 'output file'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(dataset='PROTEINS', filename='output_PROTEINS', neighbor_pooling_type='sum')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
